{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import re\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from nltk.tag import pos_tag\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TableID</th>\n",
       "      <th>ColumnID</th>\n",
       "      <th>RowID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50245608_0_871275842592178099</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39107734_2_2329160387535788734</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22864497_0_8632623712684511496</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          TableID  ColumnID  RowID\n",
       "0   50245608_0_871275842592178099         0    154\n",
       "1  39107734_2_2329160387535788734         1     32\n",
       "2  22864497_0_8632623712684511496         0    227"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = pd.read_csv(\"D:\\Dokumenty\\Zastosowanie Technologii Informatycznych\\data\\CEA_Round1_Targets.csv\",\n",
    "                    sep = ',',\n",
    "                     skiprows=range(112,113), # 112 wadliwy wiersz\n",
    "                    names=['TableID', 'ColumnID', 'RowID'])\n",
    "target[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_characters(chars_to_replace_list_of_dicts, cell_contents_list, cell_content):\n",
    "    # zamienia wszystkie znaki odpowiadające kluczowi np. '[?]' na to co w wartości ''\n",
    "    # każdy znak zamienia osobno. Nie wyszukuje stringa '[?]', tylko każdy znak po kolei szukam i zamieniam\n",
    "    for dicts in chars_to_replace_list_of_dicts:\n",
    "        for old_chars, new_char in dicts.items():\n",
    "            for old_char in old_chars:\n",
    "                cell_content = cell_content.replace(old_char, new_char)\n",
    "            if cell_content not in cell_contents_list:\n",
    "                cell_contents_list.append(cell_content)\n",
    "    return cell_contents_list\n",
    "\n",
    "def create_queries(cell_content):\n",
    "    cell_content_copy = cell_content\n",
    "    cell_contents_list = []\n",
    "    cell_contents_list.append(cell_content) # oryginalne\n",
    "    cell_contents_list.append(str('The ' + cell_content)) # opcja z The na początku\n",
    "    cell_contents_list.append(cell_content.capitalize())\n",
    "    cell_contents_list.append(cell_content.title())\n",
    "    \n",
    "    # pojawiały się wartości typy \"Guardian The\", a powinno być \"The Gurdian\", \n",
    "    # albo \"Thunderbird, Lake\", a powinno być \"Lake Thunderbird\"\n",
    "    if re.search(\", [a-zA-Z]*$\", cell_content_copy):\n",
    "        found_string = re.search(\", [a-zA-Z]*$\", cell_content_copy).group(0)\n",
    "        new_cell_content = cell_content_copy.replace(found_string, '')\n",
    "        found_string = found_string.replace(', ','')\n",
    "        new_cell_content = found_string.capitalize() + ' ' + new_cell_content\n",
    "        \n",
    "        cell_contents_list.append(new_cell_content)\n",
    "    \n",
    "    # pojawiały się wartości typy \"Guardian The\", a powinno być \"The Gurdian\" to samo z A i An\n",
    "    if re.search(\" The$\", cell_content):\n",
    "        index = cell_content.find(\" The\")\n",
    "        cell_contents_list.append(\"The \" + cell_content[:index].replace(',','').strip())\n",
    "        cell_contents_list.append(cell_content[:index].strip())\n",
    "    elif re.search(\" A$\", cell_content):\n",
    "        index = cell_content.find(\" A\")\n",
    "        cell_contents_list.append(\"A \" + cell_content[:index].replace(',','').strip())\n",
    "        cell_contents_list.append(cell_content[:index].strip())\n",
    "    elif re.search(\" An$\", cell_content):\n",
    "        index = cell_content.find(\" An\")\n",
    "        cell_contents_list.append(\"An \" + cell_content[:index].replace(',','').strip())\n",
    "        cell_contents_list.append(cell_content[:index].strip())\n",
    "\n",
    "    # usunięcię The z początku\n",
    "    if re.search(\"^The \", cell_content):\n",
    "        cell_contents_list.append(re.sub('^The ', '', cell_content))\n",
    "\n",
    "\n",
    "    strings_to_replace_dict = [{'[?]':''}, {',':''}, {'-':' '}, {'?':''}] # dict = {chars_to_replace:new_char}\n",
    "    cell_contents_list = replace_characters(strings_to_replace_dict, cell_contents_list, cell_content)\n",
    "    \n",
    "    list_of_queries = []\n",
    "    # pierwsze zapytanie - bierze zawartość sformatowanej komórki i wyszukuje linku,\n",
    "    query = 'SELECT ?resource WHERE { ?resource rdfs:label ' + '\"' + str(cell_content) + '\"' + \"@en\" + '}'\n",
    "    list_of_queries.append(query)\n",
    "\n",
    "    for cell_content in cell_contents_list:\n",
    "        query = 'SELECT ?resource WHERE { ?resource rdfs:label ' + '\"' + str(cell_content) + '\"' + \"@en\" + '} '\n",
    "        list_of_queries.append(query)\n",
    "\n",
    "\n",
    "    lang = 'en'\n",
    "    try:\n",
    "        lang = detect(cell_content)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if lang != 'en':\n",
    "        for cell_content  in cell_contents_list:\n",
    "            query = 'SELECT ?resource WHERE { ?resource rdfs:label ' + '\"' + str(cell_content) + '\"' + '@' + str(lang) + '} '\n",
    "            list_of_queries.append(query)\n",
    "    \n",
    "    return list_of_queries\n",
    "\n",
    "def create_queries_for_films(cell_content):\n",
    "    if len({'Title', 'Year'}.intersection(set(df.columns))) == 2:\n",
    "        row = df[row_id-1:row_id]\n",
    "        film_year = row['Year'].values[0]\n",
    "\n",
    "        cell_content = cell_content.replace(',','')\n",
    "        cell_content = cell_content.replace('The','')\n",
    "        cell_content = cell_content.replace(',','')\n",
    "        cell_content = cell_content.strip()\n",
    "\n",
    "\n",
    "        query1 = 'SELECT ?resource WHERE {' + \\\n",
    "                    '?resource rdfs:label ?name1 FILTER regex(?name1,'  + '\"^' + str(cell_content) + '$\", \"i\") . ' + \\\n",
    "                    '?resource rdf:type dbo:Film . }'\n",
    "\n",
    "        query2 = 'SELECT ?resource WHERE {' + \\\n",
    "                    '?resource rdfs:label ?name1 FILTER regex(?name1,'  + '\"^The ' + str(cell_content) + '$\", \"i\") . ' + \\\n",
    "                    '?resource rdf:type dbo:Film . }'\n",
    "\n",
    "        query3 = 'SELECT ?resource WHERE {' + \\\n",
    "                    '?resource rdfs:label '  + '\"' + str(cell_content) + '\" . ' + \\\n",
    "                    '?resource rdf:type dbo:Film . ' + \\\n",
    "                    '?redirect dbo:wikiPageRedirects ?resource FILTER regex(?redirect, '  + '\"' + str(film_year) + '\") . } '\n",
    "\n",
    "        query4 = 'SELECT ?resource WHERE {' + \\\n",
    "                    '?resource rdfs:label '  + '\"' + str(cell_content) + '\" . ' + \\\n",
    "                    '?resource rdf:type dbo:Film . ' + \\\n",
    "                    '?resource rdfs:label ?name2 FILTER regex(?name2, '  + '\"' + str(film_year) + '\") . }' \n",
    "\n",
    "        query5 = 'SELECT ?resource WHERE {' + \\\n",
    "                    '?resource rdfs:label ?name1 FILTER regex(?name1,'  + '\"' + str(cell_content) + '\", \"i\") . ' + \\\n",
    "                    '?resource rdf:type dbo:Film . ' + \\\n",
    "                    '?redirect dbo:wikiPageRedirects ?resource FILTER regex(?redirect, '  + '\"' + str(film_year) + '\") . } '\n",
    "\n",
    "        query6 = 'SELECT ?resource WHERE {' + \\\n",
    "                    '?resource rdfs:label ?name1 FILTER regex(?name1,'  + '\"' + str(cell_content) + '\", \"i\") . ' + \\\n",
    "                    '?resource rdf:type dbo:Film . ' + \\\n",
    "                    '?resource rdfs:label ?name2 FILTER regex(?name2, '  + '\"' + str(film_year) + '\") . }'\n",
    "\n",
    "        query7 = 'SELECT ?resource WHERE {' + \\\n",
    "                    '{?resource rdfs:label ?name1 FILTER regex(?name1,'  + '\"' + str(cell_content) + '\", \"i\") . ' + \\\n",
    "                    '?resource rdf:type dbo:Film . }}'\n",
    "\n",
    "        list_of_queries = [query1, query2, query3, query4, query5, query6, query7]\n",
    "        \n",
    "        return list_of_queries\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def send_query(query):\n",
    "    sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "\n",
    "    # jeśli wystąpi błąd z połączeniem się z serwerem to próbujemy aż do skutku\n",
    "    results = None\n",
    "    while results is None:\n",
    "        try:\n",
    "            results = sparql.query().convert()\n",
    "        except Exception as e:\n",
    "#                 print(\"EXCEPTION:\" + str(e))\n",
    "#                 print(\"TAKI: \" + str(cell_content))\n",
    "            continue\n",
    "    return results\n",
    "\n",
    "def get_URI_from_results(results, query, verbose=0):\n",
    "    # jeśli nic nie znaleziono no to trudno, nie mamy linku, wstawiamy NOT FOUND URI\n",
    "#     if cell_content_copy == 'Ruppell\\'s griffon vulture':\n",
    "#         print(query)\n",
    "    \n",
    "    if str(results['results']['bindings']).find(\"http://dbpedia.org/resource/\") == -1:\n",
    "        # printy przydatne do sprawdzania jakich zawartości nam nie wyszukał,\n",
    "        # trzeba analizowac i dodawać kolejne warunki, zmieniać cell_content na różne sposoby\n",
    "        if verbose:\n",
    "            print(table_id, column_id, row_id)\n",
    "            print(cell_content_copy)\n",
    "            print(query)    \n",
    "        return 'NOT FOUND URI'\n",
    "\n",
    "\n",
    "    # jeśli jednak mamy jakies linki to wyciągamy go z jsona,\n",
    "    # linków może być więcej niż 1, aktualnie bierzemy pierwszy lepszy\n",
    "    results_list = results['results']['bindings']\n",
    "    for result_dict in results_list:\n",
    "        uri = result_dict['resource']['value']\n",
    "        match = re.match(\"http://dbpedia.org/resource/*\", uri)\n",
    "\n",
    "        # czasami pojawiają dziwne linki np. http://dbpedia.org/resource/Category:Max_Weber\n",
    "        # my takich nie chcemy i musimy ich unikać\n",
    "        # interesują nas tylko np.  http://dbpedia.org/resource/Max_Weber\n",
    "        # więc to jest warunek pozbywajacy się wszystkich linków z Category:\n",
    "        if match and uri[5:].find(\"Category:\") == -1:\n",
    "#                 answers_dict['URI'].append(str(uri)\n",
    "#                 formatted_uri = 'http://dbpedia.org/resource/' + str(urllib.parse.quote(uri[28:]))\n",
    "#                 formatted_uri = formatted_uri.replace('-','%E2%80%93')\n",
    "            return uri\n",
    "    \n",
    "    return 'NOT FOUND URI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Pearl Harbor\n",
      "2 Minneapolis-Saint Paul International Airport\n",
      "3 Need for Speed: Carbon\n",
      "4 Alex Rodriguez\n",
      "5 King Kong\n",
      "6 School of Rock , The\n",
      "7 Lex Luger\n",
      "8 Crash Bash\n",
      "9 The Hurt Locker\n",
      "10 Lion\n",
      "11 Lac-Seul\n",
      "12 Fear and Loathing in Las Vegas\n",
      "13 Max Weber\n",
      "14 Kidsty Pike\n",
      "15 Randy Johnson\n",
      "16 TimeShift\n",
      "17 Batman: Arkham City\n",
      "18 Dazzy Vance?\n",
      "19 A Clockwork Orange\n",
      "20 Bill Collins\n",
      "21 Greenland\n",
      "22 Thunbergia grandiflora\n",
      "23 Peter of Sebaste[?]\n",
      "24 Jimmy Ryan\n",
      "25 State Hermitage Museum\n",
      "26 Mario Party 8\n",
      "27 Lygodium palmatum\n",
      "28 New Taiwan Dollar\n",
      "29 Mary Poppins\n",
      "30 The Curse of Monkey Island\n",
      "31 Super Mario All-Stars + Super Mario World\n",
      "32 Ruppell's griffon vulture\n",
      "13719111_1_5719401842463579519 0 48\n",
      "Ruppell's griffon vulture\n",
      "33 Contender\n",
      "34 Common fiscal\n",
      "35 Heat\n",
      "36 Pope Linus\n",
      "37 Broken Bow Lake\n",
      "38 TREE SWALLOW\n",
      "39 The Wild Bunch\n",
      "40 FIFA 08\n",
      "41 The Legend of Zelda: Ocarina of Time\n",
      "42 Fellbarrow\n",
      "43 Sim City\n",
      "44 Asparagus densiflorus\n",
      "45 To Be or Not to Be\n",
      "46 John of the Cross\n",
      "47 Mark Langston\n",
      "48 Soldier of Fortune: Pay Back\n",
      "49 Life as A House\n",
      "50 Dusky turtle dove\n",
      "51 My Cousin Vinny\n",
      "52 The Book of Eli\n",
      "53 Kaw lake\n",
      "54 Paulinus of Nola\n",
      "55 Three Kings\n",
      "56 ORCHARD ORIOLE\n",
      "57 Swingers\n",
      "58 Poa cusickii\n",
      "59 Ice Harvest\n",
      "60 Litsea glutinosa\n",
      "61 Die Sims\n",
      "62 Donkey Kong Country\n",
      "63 Wood sandpiper\n",
      "64 Melbourne Airport\n",
      "65 Calf Crag\n",
      "66 Mexican\n",
      "67 Blue-shouldered robin-chat\n",
      "68 White-browed scrub-robin\n",
      "69 Metroid Prime\n",
      "70 San Diego Museum of Art\n",
      "71 Pitcairn Islands\n",
      "72 Lingmoor Fell\n",
      "73 James Cameron's Avatar: The Game\n",
      "74 Croaking cisticola\n",
      "75 The Battleship Potemkin\n",
      "76 Rijksmuseum\n",
      "77 Hennessy\n",
      "78 Andropogon hallii\n",
      "79 Das Boot\n",
      "80 Star Wars: Clone Wars\n",
      "81 Bosnia and Herzegovina\n",
      "82 Gran Turismo 3 A-spec\n",
      "83 Dead Poets Society\n",
      "84 Tootsie\n",
      "85 Blue-spotted wood-dove\n",
      "86 Legend of Zelda: Majora's MaskThe Legend of Zelda: Majora's Mask\n",
      "75367212_2_2745466355267233390 0 16\n",
      "Legend of Zelda: Majora's MaskThe Legend of Zelda: Majora's Mask\n",
      "87 EASTERN CHIPMUNK\n",
      "88 Pope Innocent I\n",
      "89 Archives of Internal Medicine\n",
      "90 St Helena Pound\n",
      "26310680_0_5150772059999313798 1 193\n",
      "St Helena Pound\n",
      "91 Thunderbird, Lake\n",
      "92 Harlan County Lake\n",
      "93 Godfather, The\n",
      "94 Midnight Club 2\n",
      "95 Acacia longifolia\n",
      "96 Face/Off\n",
      "97 SingStar Pop Hits\n",
      "98 SEGA Rally Revo\n",
      "99 Namibia\n",
      "15.959242582321167\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# słownik, z którego będzie tworzony wynikowy df\n",
    "answers_dict = {\"TableID\":[],\n",
    "               \"ColumnID\":[],\n",
    "               \"RowID\":[],\n",
    "               \"URI\":[]}\n",
    "\n",
    "# zmienna, aby ograniczyć liczbę przetwarzanych wierszy, niżej masz 3 linijki skomentowane,\n",
    "# odkomentowujesz je i ustawiasz sobię liczbę wierszy w tym warunku, aktualnie 1000\n",
    "counter = 0\n",
    "# zlicza ile linków nie zostało znalezionych w ogóle,\n",
    "# tzn. po wysłaniu zapytania nie dostaliśmy żądnej odpwiedzi od sparql (wiersze oznaczone przez NOT FOUND URI)\n",
    "not_found_uris = 0\n",
    "\n",
    "for index, row in target.iterrows():\n",
    "    try:\n",
    "        counter = counter + 1\n",
    "        if counter == 100:\n",
    "            break\n",
    "\n",
    "\n",
    "        table_id = row['TableID']\n",
    "        column_id = row['ColumnID']\n",
    "        row_id = row['RowID']\n",
    "        \n",
    "        # wczytanie odpowiedniej tabeli\n",
    "        df = pd.read_csv(f\"D:\\Dokumenty\\Zastosowanie Technologii Informatycznych\\data\\CEA_Round1\\{table_id}.csv\",\n",
    "                    sep=',')\n",
    "        \n",
    "            \n",
    "        # wyciągniecie wartości komórki, która nas interesuje\n",
    "        cell_content = df.iloc[row_id-1:row_id, column_id:(column_id+1)].values[0][0]\n",
    "        cell_content_copy = cell_content\n",
    "        \n",
    "        print(str(counter) + ' ' + cell_content)\n",
    "        \n",
    "        # usunięcie białych znaków z początku i końca stringa\n",
    "        cell_content = cell_content.strip()\n",
    "        \n",
    "        list_of_queries = []\n",
    "        list_of_queries += create_queries_for_films(cell_content)\n",
    "        list_of_queries = list_of_queries + create_queries(cell_content)\n",
    "        \n",
    "        for id, query in enumerate(list_of_queries):\n",
    "            results = send_query(query)                              \n",
    "            uri = get_URI_from_results(results, query, verbose=0)\n",
    "\n",
    "            if uri != 'NOT FOUND URI':             \n",
    "                answers_dict['TableID'].append(table_id)\n",
    "                answers_dict['ColumnID'].append(column_id)\n",
    "                answers_dict['RowID'].append(row_id)\n",
    "                answers_dict['URI'].append(uri)\n",
    "                break\n",
    "            elif id+1 == len(list_of_queries) and uri == 'NOT FOUND URI':\n",
    "                answers_dict['TableID'].append(table_id)\n",
    "                answers_dict['ColumnID'].append(column_id)\n",
    "                answers_dict['RowID'].append(row_id)\n",
    "                answers_dict['URI'].append(\"NOT FOUND URI\")\n",
    "                not_found_uris += 1\n",
    "                \n",
    "                print(table_id, column_id, row_id)\n",
    "                print(cell_content_copy)\n",
    "                \n",
    "                    \n",
    "\n",
    "        # aktualnie nie używane, ale pewnie będzie\n",
    "        # pos_tag() - kategoryzuje słowa, np. znajduje czasowniki, rzeczowniki, nazwy własne (jak imiona i nazwiska)\n",
    "        # chodzi o to, że czasami odpowiedzi są w angielskiej dbpedii,\n",
    "        # np. Alex Rodriguez wykrywa jako język ca - pewnie kataloński, \n",
    "        # ale nie ma jego odpowiednika w katalońskiej dbpedii, a w angielskiej jest\n",
    "        # dlatego chcę wykrywać nazwy wkłasne jak imiona i nazwiska i wtedy zawsze szukać w angielksiej dbpedii,\n",
    "        # ale z tym też był problem czasami i na razie nie myślałem nad tym dalej\n",
    "        # NNP - to kategoria nazwy własnej, np. imię\n",
    "#         tags = pos_tag(cell_content.split())\n",
    "#         is_one_NNP = False\n",
    "#         for tag in tags:\n",
    "#             if tag[1] == \"NNP\":\n",
    "#                 is_one_NNP = True\n",
    "#                 break\n",
    "#         try:\n",
    "#             if is_one_NNP:\n",
    "#                 lang = '@en'\n",
    "#             else:\n",
    "#                 lang = str('@') + str(detect(cell_content))\n",
    "#         except Exception:\n",
    "#             lang = ''\n",
    "\n",
    "#         list_of_queries = create_queries(cell_content)\n",
    "#         for query in list_of_queries:\n",
    "#             results = send_query(query)                              \n",
    "#             uri = get_URI_from_results(results, query, verbose=1) \n",
    "                         \n",
    "#             answers_dict['TableID'].append(table_id)\n",
    "#             answers_dict['ColumnID'].append(column_id)\n",
    "#             answers_dict['RowID'].append(row_id)\n",
    "#             answers_dict['URI'].append(uri)\n",
    "#             if uri == 'NOT FOUND URI':\n",
    "#                 not_found_uris += 1\n",
    "#                 continue\n",
    "\n",
    "    except Exception as e:\n",
    "        # na początku były problemy z danymi, naprawiłem\n",
    "        # potem zaczęły pojawiać sę problemy, żę serwer czasami nie odpowiadał,\n",
    "        # więc jak jest error to olewamy i przechodzimy do następnego wiersza\n",
    "        # będzie trzeba zrobić, że jak serwer nie odpowie z jakiegoś powodu to trzeba ponowić to samo zapytanie\n",
    "        # zamiast pomijać, bo tracimy wiersze\n",
    "        exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "        print(table_id, column_id, row_id) # jaki plik, kolumna i wiersz\n",
    "        print(cell_content_copy) # zawartość komórki\n",
    "        print(e) # jaki błąd, teraz chyba tylko z brakiem połączenia z serwerem\n",
    "        print(exc_tb.tb_lineno) # w jakiej liniii błąd\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "# print(answers_dict)\n",
    "result_df = pd.DataFrame(answers_dict)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "print(not_found_uris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_df.shape)\n",
    "print(target.shape)\n",
    "result_df[:20]\n",
    "# result_df[10:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zapisanie submission\n",
    "# przez evaluator codes można sprawdzić wyniki\n",
    "result_df.to_csv(\"D:\\Dokumenty\\Zastosowanie Technologii Informatycznych\\evaluator_codes\\evaluator_codes\\data\\my_submission_films2.csv\",\n",
    "                 index=False,\n",
    "                 sep=',',\n",
    "                header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NIEISTOTNE, TESTY ITP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\\\Dokumenty\\\\Zastosowanie Technologii Informatycznych\\\\data\\\\CEA_Round1\\\\13719111_1_5719401842463579519.csv\",\n",
    "                sep=',')\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect(df.iloc[0:1, 1:2].values[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "sparql.setQuery(\"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    SELECT ?label\n",
    "    WHERE { <http://dbpedia.org/resource/Norway> rdfs:label ?label }\n",
    "\"\"\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "\n",
    "print(results)\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    print(result[\"label\"][\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "sparql.setQuery(\"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX ont: <http://dbpedia.org/ontology/>\n",
    "    SELECT ?a, ?c\n",
    "    WHERE { \n",
    "            ?a ont:location <http://dbpedia.org/resource/Delft> . \n",
    "            FILTER regex(?a, \"Ikea\", \"i\")\n",
    "          }\n",
    "\"\"\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "\n",
    "print(results)\n",
    "# print(result['a'])\n",
    "# print(result['b'])\n",
    "# print(result['c'])\n",
    "\n",
    "# for result in results[\"results\"][\"bindings\"]:\n",
    "#     print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "sss = \"dbr:Game_of_Thrones\"\n",
    "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "sparql.setQuery('''\n",
    "ASK {e}\n",
    "    VALUES (?r) {e} ({source}) {w}\n",
    "        {e} ?r ?p ?o {w}\n",
    "        UNION\n",
    "        {e} ?s ?r ?o {w}\n",
    "        UNION\n",
    "        {e} ?s ?p ?r {w}\n",
    "    {w} \n",
    "'''.format(source=sss, e=\"{\", w=\"}\"))\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "sss = \"dbr:Game_of_Thrones\"\n",
    "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "sparql.setQuery('''\n",
    "ASK {\n",
    "    VALUES (?r) { (dbr:Gra_o_tron) }\n",
    "        { ?r ?p ?o }\n",
    "        UNION\n",
    "        { ?s ?r ?o }\n",
    "        UNION\n",
    "        { ?s ?p ?r }\n",
    "    } \n",
    "''')\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "\n",
    "print(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT ?r ?p ?o\n",
    "WHERE {\n",
    " VALUES (?r) { (dbr:Cat) }\n",
    "        { ?r ?p ?o }\n",
    "        UNION\n",
    "        { ?s ?r ?o }\n",
    "        UNION\n",
    "        { ?s ?p ?r }\n",
    "}\n",
    "\n",
    "select ?s\n",
    "where {\n",
    "        { ?s rdfs:label \"Kot domowy\"@pl }\n",
    "        UNION\n",
    "        { \"Kot domowy\"@pl rdfs:label ?s }\n",
    "} \n",
    "\n",
    "SELECT ?r\n",
    "WHERE {\n",
    "        { ?r rdfs:label \"Kaspisches Meer\"@de }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "sparql.setQuery(\"\"\"\n",
    "    SELECT ?resource\n",
    "    WHERE { ?resource rdfs:label \"Kaspisches Meer\"@de }\n",
    "\"\"\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "# print(results['results']['bindings'][1]['r']['value'])\n",
    "# results = str(results['results']['bindings'])\n",
    "print(str(results['results']['bindings']))\n",
    "if str(results['results']['bindings']).find(\"http://dbpedia.org/resource/\") == -1:\n",
    "    print(\"nie ma\")\n",
    "else:\n",
    "    print('jest')\n",
    "# for result_dict in results_list:\n",
    "#     uri = result_dict['resource']['value']\n",
    "#     match = re.match(\"http://dbpedia.org/resource/*\", uri)\n",
    "#     if match:\n",
    "#         print(uri)\n",
    "#     else:\n",
    "#         print(\"NIE\")\n",
    "\n",
    "# print(results['results']['bindings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "match = re.match(\"http://dbpedia.org/resource/*\",'http://dbpedia.org/resource/Caspian_Sea', re.M|re.I)\n",
    "if match:\n",
    "    print(match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
